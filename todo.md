# TODO.md — Proyecto: Portal de Noticias Automático

**Resumen:**
Portal de noticias totalmente automático con frontend en **React** (diseño moderno, aspecto tecnológico, luces brillantes y animaciones) y backend en **Java Spring Boot**. Sistema CI/CD que encuentra noticias en internet, las reescribe con una IA mediante prompts, genera y edita imágenes relacionadas con IA, ofrece backoffice para moderación/edición, autenticación, comentarios por noticia, y generación/automatización de placas para redes sociales.

---

## Fase 0 — Consideraciones previas (Riesgos, legales y éticos)
- **Revisión legal y derechos de autor:** documentar políticas de uso de contenido encontrado en la web. Implementar filtros de copyright y atribución mínima. Consultar un abogado si planeas publicar contenido derivado masivamente.
- **Moderación y seguridad:** sistema de detección de discurso de odio, desinformación y contenido sensible. Registrar decisiones de la IA (audit log).
- **Responsabilidad editorial:** marcar contenido generado por IA. Permitir intervención humana vía backoffice.

---

## Fase 1 — Diseño de arquitectura (alto nivel)
- **Frontend (React):** Vite + React 18, Tailwind CSS, Framer Motion para animaciones, librería de componentes (opcional: shadcn/ui). Organización: `src/components`, `src/pages`, `src/lib`, `src/hooks`, `src/store`.
- **Backend (Spring Boot):** Java 17+, Spring Boot, Spring Security (OAuth2/JWT), Spring Data JPA (PostgreSQL), Redis (caching, rate-limit), servicio de colas (RabbitMQ o Kafka) para pipelines asíncronos.
- **Servicio de ingestion / scraping:** microservicio (recomendado: Python + Scrapy o Node.js + Puppeteer) que envía noticias crudas al backend mediante API o cola.
- **Pipeline LLM + generación imágenes:** componente (microservicio) que recibe texto bruto, ejecuta prompt a LLM (OpenAI/otro), produce texto reescrito + metadata; otro componente llama a generador de imágenes (Stable Diffusion / DALL·E / API), guarda imágenes en CDN.
- **CI/CD / Orquestación:** GitHub Actions (o GitLab CI) para tests y despliegues; pipeline programado (cron) para ejecutar scraping -> reescritura -> subida.
- **Almacenamiento:** PostgreSQL para datos relacionales, S3-compatible (DigitalOcean Spaces / AWS S3) para assets, Redis para cache.
- **Despliegue:** Kubernetes (recommended) o Docker Compose para POC; Vercel/Netlify para frontend; backend en Kubernetes/Render/Heroku.

---

## Fase 2 — Definición del MVP (entregable mínimo)
**Objetivos mínimos:**
1. Frontend: listado de noticias, página de noticia con imagen y comentarios.
2. Backend: CRUD de noticias, autenticación básica con JWT, endpoints para comments, roles `ADMIN` y `EDITOR`.
3. Pipeline simple: scheduler que toma feeds RSS de 3 sitios, crea noticia en DB con flag `auto_generated=true`.
4. Backoffice básico: lista de noticias auto-generadas, editar/rechazar y publicar.
5. Generación de imagen automática vía API de generación de imágenes.
6. Sistema de comentarios con moderación manual.

---

## Fase 3 — Especificación de componentes y tareas (por módulos)

### 3.1 Backend — Spring Boot
- Crear proyecto Spring Boot con módulos:
  - `api` (REST controllers)
  - `service` (lógica de negocio)
  - `repository` (Spring Data JPA)
  - `security` (configuración JWT/OAuth)
  - `jobs` (scheduled tasks / worker consumers)
- Entidades principales: `News` (id, title, body, excerpt, authorsource, url_source, images[], tags[], status[draft|published|rejected], publishedAt, autoGenerated boolean, generatedByJobId), `User`, `Comment`, `MediaAsset`, `AuditLog`.
- Endpoints REST:
  - `POST /api/auth/login` — JWT
  - `GET /api/news` — filtros, paginación
  - `GET /api/news/{id}`
  - `POST /api/news` — crear manual
  - `PUT /api/news/{id}` — editar
  - `POST /api/news/{id}/publish` — publicar
  - `POST /api/news/{id}/comments` — agregar comentario
  - Admin-only: `GET /api/backoffice/auto-generated` — lista pendientes
- Seguridad:
  - JWT con roles `ROLE_ADMIN`, `ROLE_EDITOR`, `ROLE_USER`.
  - Rate-limits para endpoints públicos (usar Redis + bucket token).
- Integración con queue: producer/consumer para procesar jobs (e.g., `news_ingest`, `news_rewrite`, `media_generate`).
- Tests unitarios + integración (H2) + contract tests para endpoints más críticos.

### 3.2 Frontend — React
- Stack: Vite + React + TypeScript, Tailwind, Framer Motion, react-query (o SWR) para fetch de datos, react-router.
- Páginas:
  - Home / grid de noticias (cards con efecto brillante, hover animaciones)
  - Página noticia (hero image, cuerpo, comentarios, compartir en redes)
  - Backoffice: login / panel: lista, editor WYSIWYG (Tip: use TipTap or Slate), revisión de noticias auto-generadas, edición de imágenes (preview + prompt)
  - Settings: conectar cuentas de redes sociales (API keys) para automatización de publicaciones
- Componentes UI:
  - Card de noticia con neon/glow, micro-animaciones con Framer Motion
  - Editor de texto enriquecido con versionado (guardar draft + cambios)
  - Modal para revisión de imagen generada y edición del prompt
- Internacionalización (i18n) opcional.

### 3.3 Servicio de Ingestión (scraper)
- Implementar microservicio separado:
  - Input: configuraciones de fuentes (RSS, selectores CSS, dominios), frecuencia por fuente.
  - Output: JSON con `{title, body_html, excerpt, source_url, publishedAt, images[]}` enviado al backend via API o puesto en cola.
- Reglas:
  - Respectar `robots.txt` y politicas de los sitios. Implementar throttle y backoff.
  - Metadata: autor, fecha original, licencia aparente.

### 3.4 Servicio de Rewriting (LLM)
- Microservicio que consume items de `news_ingest`:
  - Ejecuta pipeline: limpieza HTML -> extraer texto -> generar prompt -> enviar a LLM -> obtener reescritura.
  - Prompt template (ver abajo en sección de prompts).
  - Añadir step de `safety_check` (moderar por toxicidad, veracidad cuestionable).
  - Guardar versión original + reescrita en `AuditLog`.

### 3.5 Servicio de generación de imágenes
- Para cada noticia, generar 1..3 imágenes:
  - Buscar imágenes relacionadas (crawl image search o usar `image_url` del artículo).
  - Enviar imágenes y/o prompts a generador IA para crear variantes "neutrales".
  - Guardar versiones y crear thumbnails para redes.
  - Permitir edición humana en backoffice (ajustar prompt, recortar, reemplazar).

### 3.6 Automatización de publicaciones a redes
- Componente que: cuando noticia se publica (status=published), crea placa (social card) y encola publicación.
- Generador de placa: usar headless browser (Puppeteer) o server-side rendering para generar PNG de plantilla con título, autor, logo y fondo.
- Integraciones: Twitter/X API, Facebook API, Instagram (via Meta tools), LinkedIn, plus posibilidad de exportar para Buffer/Hootsuite.
- Programación: permitir cola y schedule (publicar en horario óptimo).

### 3.7 Sistema de comentarios
- Features:
  - Comentarios anidados hasta X niveles.
  - Moderación: reportes, bloqueo, filtros automáticos (palabras prohibidas), captchas para reducir spam.
  - Opciones para login social (Google, Twitter) y guest comments con email verificación.
  - WebSockets para actualizaciones en tiempo real (Spring WebSocket / STOMP).

### 3.8 Backoffice (CMS)
- Roles: Admin, Editor, Moderator.
- Features:
  - Cola de noticias auto-generadas: editar, aceptar, rechazar.
  - Editor WYSIWYG con historial y notas de AI (mostrar prompt usado + LLM metadata).
  - Gestión de assets (imágenes), re-generación desde prompt, edición rápida.
  - Logs de auditoría y revertir cambios.

---

## Fase 4 — Prompts y templates (bloque crítico)
A continuación un prompt *base* para la reescritura (adaptar por tu LLM):

**Prompt - Rewriter (template)**
```
Eres un redactor profesional de noticias. Toma el siguiente texto fuente ("SOURCE_TEXT"), su origen ("SOURCE_NAME" y "SOURCE_URL"), y genera un nuevo artículo en español neutro, estilo periodístico, 3 párrafos cortos y un título llamativo de máximo 80 caracteres. Mantén los hechos verificables; si hay afirmaciones no verificables, marca con [NO_VERIFICADO]. No inventes citas. Incluye un resumen (excerpt) de 160 caracteres y 3 tags sugeridos.

SOURCE_NAME: {{source_name}}
SOURCE_URL: {{source_url}}
SOURCE_TEXT:
"""
{{source_text}}
"""

INSTRUCCIONES:
- Conserva hechos comprobables (fechas, nombres, cifras) exactamente como están.
- Cambia la redacción para evitar plagio directo: reestructura oraciones, usa sinónimos y cambia el orden informativo.
- Si el contenido es opinión, etiquétalo como "opinion" en tags.
- Devuelve JSON válido con campos: title, excerpt, body_html, tags[], warnings[]
```

**Prompt - Image Gen (template)**
```
Genera una imagen editorial relacionada con el siguiente artículo. Estilo: moderno, tecnológico, luces brillantes, high-contrast, composición para hero image de web (landscape). No incluir personas reconocibles.
TEXT_PROMPT: "{{short_description}}"
CONSTRAINTS: neutral tone, sin símbolos políticos explícitos, resolución preferida 1920x1080.
Return: prompt listo para usar en el generador de imágenes.
```

**Nota:** guardar prompts y outputs en la base de datos para trazabilidad.

---

## Fase 5 — CI/CD y pipelines automáticos
- **Repos:** `frontend` (React), `backend` (Spring Boot), `services/scraper`, `services/rewriter`, `infra` (k8s manifests, helm).
- **Workflows (GitHub Actions):**
  - `on: push` -> build/test -> deploy (staging/production)
  - `on: schedule` (cron) -> trigger `scraper` job -> push raw items to queue
  - `on: workflow_run` -> when `scraper` complete -> trigger `rewriter` -> image generation -> push to backend via API
- **Jobs:** container build, security scan (Snyk), dependency audit, unit + integration tests.
- **Rollback:** keep tagged images, DB migrations via Flyway; create health checks.

---

## Fase 6 — Observabilidad, métricas y monitoreo
- **Logs centralizados:** ELK stack or Loki + Grafana.
- **Tracing:** OpenTelemetry for cross-service traceability.
- **Metrics:** Nº noticias generadas/día, ratio aceptadas/rechazadas, latency de pipelines, tasa de error LLM, uso de cuota API.
- **Alerting:** PagerDuty or simple email/Slack alerts en fallas críticas.

---

## Fase 7 — Seguridad y hardening
- Encriptar secretos (Vault / GitHub Secrets).
- CSP y XSS protection en frontend; sanitizar HTML en backend.
- Validaciones exhaustivas en endpoints públicos.
- Protección contra scraping malicioso (usar rate-limits y reCAPTCHA donde aplique).

---

## Fase 8 — Tests y QA
- Tests unitarios backend y frontend.
- Tests E2E con Playwright (cobertura: publicar noticia, backoffice aceptar, ver noticia en frontend, generar placa).
- Tests de pipeline: mockear API de LLM e imagen para pruebas offline.

---

## Fase 9 — Roadmap de entrega (sprints sugeridos)
- Sprint 1 (2 semanas): Infra básica, backend CRUD, DB, frontend layout básico.
- Sprint 2 (2 semanas): Auth, comments, simple backoffice, tests básicos.
- Sprint 3 (2 semanas): Scraper POC, ingestion into DB, basic pipeline manual.
- Sprint 4 (2 semanas): Rewriter POC con LLM, image gen POC, display in frontend.
- Sprint 5 (2 semanas): CI/CD schedule, automated end-to-end flow, moderation UI.
- Sprint 6 (2 semanas): Social card generator, social integration, analytics.

---

## Fase 10 — Lista TODO granular (tickets que puede copiarse a GitHub Issues)

### Infra
- [ ] Crear repos monorepo o multi-repos.
- [ ] Definir infraestructura (k8s / docker-compose).
- [ ] Configurar base de datos PostgreSQL y S3.

### Backend
- [ ] Scaffold Spring Boot project + modules.
- [ ] Modelar entidades y repositorios.
- [ ] Implementar endpoints CRUD de `News`.
- [ ] Implementar seguridad JWT y roles.
- [ ] Crear job consumer para `news_ingest`.
- [ ] Implementar APIs para backoffice.
- [ ] Implementar moderation endpoints.
- [ ] Integración con Redis y RabbitMQ.

### Frontend
- [ ] Scaffold React + Tailwind.
- [ ] Implementar layout y theme neon/tech.
- [ ] Cards animadas en Home.
- [ ] Página noticia con comments.
- [ ] Backoffice: lista y editor con previews.

### Servicios AI
- [ ] Scraper básico (RSS sources).
- [ ] Rewriter service con LLM integration + prompt store.
- [ ] Image generation service.
- [ ] Pipeline orchestration (queue consumers).

### CI/CD
- [ ] GitHub Actions: build/test/deploy.
- [ ] Scheduled scraping workflow.
- [ ] Secrets management.

### Operaciones & monitoreo
- [ ] Integrar logs y metrics.
- [ ] Implementar alerting básico.

---

## Fase 11 — Criterios de aceptación (QA)
- Una noticia tomada por scraper aparece en la cola y puede ser reescrita por LLM.
- Un editor puede revisar y modificar la noticia en backoffice y publicarla.
- Al publicar, la noticia aparece en frontend con imagen y se genera una placa social.
- Los comentarios funcionan y permiten moderación.
- Pipeline registra auditoría (prompt usado, LLM id, imagen prompts).

---

## Fase 12 — Consideraciones finales y extensiones
- Añadir detección de deepfakes y verificación multimodal.
- Implementar personalización de feed según preferencias del usuario.
- Soporte multi-idioma y syndication a apps móviles.

---

## Anexos rápidos: ejemplos de herramientas y libs (sugerencias)
- Frontend: Vite, React, Tailwind, Framer Motion, react-query, TipTap.
- Backend: Spring Boot, Spring Security, Spring Data JPA, Flyway, Lombok.
- DB / Cache: PostgreSQL, Redis.
- Queue: RabbitMQ o Kafka.
- Scraper: Scrapy (Python) / Puppeteer (Node).
- LLM: OpenAI API, Anthropic, o LLM local.
- Image Gen: DALL·E, Stable Diffusion via API.
- CI/CD: GitHub Actions.
- Infra: Kubernetes, Helm, Docker, Traefik/NGINX.

---

> **Importante:** Este TODO.md es una guía técnica de alto detalle. Antes de montar pipelines que reescriban contenido de terceros revisá las leyes de tu país y las políticas de los sitios fuente. Implementá controles humanos para evitar la propagación de desinformación.


***Fin del TODO.md***

